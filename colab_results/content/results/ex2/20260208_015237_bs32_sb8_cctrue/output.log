2026-02-08:01:52:47 WARNING  [config.evaluate_config:281] --limit SHOULD ONLY BE USED FOR TESTING. REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2026-02-08:01:52:51 INFO     [_cli.run:376] Selected Tasks: ['lambada_openai']
2026-02-08:01:52:53 INFO     [evaluator:211] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2026-02-08:01:52:53 INFO     [evaluator:236] Initializing hf model, with arguments: {'pretrained': 'meta-llama/Llama-3.2-1B'}
2026-02-08:01:52:55 INFO     [models.huggingface:161] Using device 'cuda:0'
2026-02-08:01:52:57 INFO     [models.huggingface:423] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
2026-02-08 01:52:58.634133: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1770515578.655615   13352 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1770515578.664276   13352 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1770515578.683744   13352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1770515578.683770   13352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1770515578.683773   13352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1770515578.683775   13352 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-02-08 01:52:58.687834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2026-02-08:01:53:08 INFO     [tasks:700] Selected tasks:
2026-02-08:01:53:08 INFO     [tasks:691] Task: lambada_openai (lambada/lambada_openai.yaml)
2026-02-08:01:53:08 INFO     [api.task:311] Building contexts for lambada_openai on rank 0...
  0%|          | 0/1289 [00:00<?, ?it/s]  2%|▏         | 30/1289 [00:00<00:04, 292.59it/s]  5%|▍         | 60/1289 [00:00<00:04, 290.65it/s]  7%|▋         | 90/1289 [00:00<00:04, 283.04it/s]  9%|▉         | 119/1289 [00:00<00:04, 284.85it/s] 11%|█▏        | 148/1289 [00:00<00:04, 281.75it/s] 14%|█▎        | 177/1289 [00:00<00:04, 276.98it/s] 16%|█▌        | 206/1289 [00:00<00:03, 280.17it/s] 18%|█▊        | 235/1289 [00:00<00:03, 276.86it/s] 20%|██        | 264/1289 [00:00<00:03, 278.62it/s] 23%|██▎       | 292/1289 [00:01<00:03, 276.44it/s] 25%|██▍       | 320/1289 [00:01<00:03, 273.93it/s] 27%|██▋       | 348/1289 [00:01<00:03, 272.44it/s] 29%|██▉       | 376/1289 [00:01<00:03, 269.59it/s] 33%|███▎      | 419/1289 [00:01<00:02, 314.73it/s] 36%|███▌      | 460/1289 [00:01<00:02, 342.49it/s] 39%|███▉      | 502/1289 [00:01<00:02, 364.14it/s] 42%|████▏     | 544/1289 [00:01<00:01, 380.07it/s] 46%|████▌     | 587/1289 [00:01<00:01, 393.36it/s] 49%|████▉     | 630/1289 [00:01<00:01, 402.71it/s] 52%|█████▏    | 673/1289 [00:02<00:01, 409.01it/s] 55%|█████▌    | 715/1289 [00:02<00:01, 412.16it/s] 59%|█████▉    | 758/1289 [00:02<00:01, 416.10it/s] 62%|██████▏   | 800/1289 [00:02<00:01, 404.24it/s] 65%|██████▌   | 843/1289 [00:02<00:01, 409.80it/s] 69%|██████▊   | 885/1289 [00:02<00:00, 411.49it/s] 72%|███████▏  | 928/1289 [00:02<00:00, 414.21it/s] 75%|███████▌  | 970/1289 [00:02<00:00, 415.64it/s] 79%|███████▊  | 1012/1289 [00:02<00:00, 415.70it/s] 82%|████████▏ | 1055/1289 [00:02<00:00, 418.91it/s] 85%|████████▌ | 1098/1289 [00:03<00:00, 421.95it/s] 89%|████████▊ | 1141/1289 [00:03<00:00, 421.06it/s] 92%|█████████▏| 1184/1289 [00:03<00:00, 419.54it/s] 95%|█████████▌| 1226/1289 [00:03<00:00, 407.66it/s] 98%|█████████▊| 1267/1289 [00:03<00:00, 407.89it/s]100%|██████████| 1289/1289 [00:03<00:00, 362.54it/s]
2026-02-08:01:53:12 INFO     [evaluator:584] Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/1289 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1551: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)
  return _C._get_float32_matmul_precision()
Running loglikelihood requests:   0%|          | 1/1289 [00:08<2:54:22,  8.12s/it]Running loglikelihood requests:   3%|▎         | 33/1289 [00:11<05:47,  3.61it/s] Running loglikelihood requests:   5%|▌         | 65/1289 [00:14<03:31,  5.79it/s]Running loglikelihood requests:   8%|▊         | 97/1289 [00:17<02:44,  7.23it/s]Running loglikelihood requests:  10%|█         | 129/1289 [00:20<02:19,  8.29it/s]Running loglikelihood requests:  12%|█▏        | 161/1289 [00:23<02:04,  9.06it/s]Running loglikelihood requests:  15%|█▍        | 193/1289 [00:26<01:53,  9.66it/s]Running loglikelihood requests:  17%|█▋        | 225/1289 [00:29<01:45, 10.13it/s]Running loglikelihood requests:  20%|█▉        | 257/1289 [00:32<01:38, 10.51it/s]Running loglikelihood requests:  22%|██▏       | 289/1289 [00:35<01:32, 10.79it/s]Running loglikelihood requests:  25%|██▍       | 321/1289 [00:37<01:27, 11.04it/s]Running loglikelihood requests:  27%|██▋       | 353/1289 [00:40<01:22, 11.30it/s]Running loglikelihood requests:  30%|██▉       | 385/1289 [00:43<01:18, 11.49it/s]Running loglikelihood requests:  32%|███▏      | 417/1289 [00:45<01:14, 11.64it/s]Running loglikelihood requests:  35%|███▍      | 449/1289 [00:48<01:11, 11.83it/s]Running loglikelihood requests:  37%|███▋      | 481/1289 [00:50<01:07, 11.99it/s]Running loglikelihood requests:  40%|███▉      | 513/1289 [00:53<01:03, 12.20it/s]Running loglikelihood requests:  42%|████▏     | 545/1289 [00:55<01:00, 12.37it/s]Running loglikelihood requests:  45%|████▍     | 577/1289 [00:58<00:56, 12.51it/s]Running loglikelihood requests:  47%|████▋     | 609/1289 [01:00<00:53, 12.68it/s]Running loglikelihood requests:  50%|████▉     | 641/1289 [01:03<00:50, 12.83it/s]Running loglikelihood requests:  52%|█████▏    | 673/1289 [01:05<00:47, 12.94it/s]Running loglikelihood requests:  55%|█████▍    | 705/1289 [01:08<00:44, 13.12it/s]Running loglikelihood requests:  57%|█████▋    | 737/1289 [01:10<00:41, 13.26it/s]Running loglikelihood requests:  60%|█████▉    | 769/1289 [01:12<00:38, 13.37it/s]Running loglikelihood requests:  62%|██████▏   | 801/1289 [01:15<00:36, 13.56it/s]Running loglikelihood requests:  65%|██████▍   | 833/1289 [01:17<00:33, 13.69it/s]Running loglikelihood requests:  67%|██████▋   | 865/1289 [01:19<00:30, 13.79it/s]Running loglikelihood requests:  70%|██████▉   | 897/1289 [01:21<00:28, 13.86it/s]Running loglikelihood requests:  72%|███████▏  | 929/1289 [01:24<00:25, 14.00it/s]Running loglikelihood requests:  75%|███████▍  | 961/1289 [01:26<00:23, 14.12it/s]Running loglikelihood requests:  77%|███████▋  | 993/1289 [01:28<00:20, 14.19it/s]Running loglikelihood requests:  80%|███████▉  | 1025/1289 [01:30<00:18, 14.36it/s]Running loglikelihood requests:  82%|████████▏ | 1057/1289 [01:32<00:16, 14.49it/s]Running loglikelihood requests:  84%|████████▍ | 1089/1289 [01:35<00:13, 14.57it/s]Running loglikelihood requests:  87%|████████▋ | 1121/1289 [01:37<00:11, 14.76it/s]Running loglikelihood requests:  89%|████████▉ | 1153/1289 [01:39<00:09, 14.91it/s]Running loglikelihood requests:  92%|█████████▏| 1185/1289 [01:41<00:06, 15.12it/s]Running loglikelihood requests:  94%|█████████▍| 1217/1289 [01:43<00:04, 15.27it/s]Running loglikelihood requests:  97%|█████████▋| 1249/1289 [01:45<00:02, 15.54it/s]Running loglikelihood requests:  99%|█████████▉| 1281/1289 [01:45<00:00, 19.78it/s]Running loglikelihood requests: 100%|██████████| 1289/1289 [01:45<00:00, 12.16it/s]
bootstrapping for stddev: perplexity
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:29,  3.37it/s]  3%|▎         | 3/100 [00:00<00:19,  5.07it/s]  5%|▌         | 5/100 [00:01<00:19,  4.82it/s]  7%|▋         | 7/100 [00:01<00:14,  6.25it/s]  8%|▊         | 8/100 [00:01<00:13,  6.77it/s]  9%|▉         | 9/100 [00:01<00:12,  7.19it/s] 10%|█         | 10/100 [00:01<00:11,  7.69it/s] 11%|█         | 11/100 [00:01<00:11,  7.73it/s] 12%|█▏        | 12/100 [00:01<00:10,  8.10it/s] 13%|█▎        | 13/100 [00:01<00:10,  8.29it/s] 14%|█▍        | 14/100 [00:02<00:10,  8.15it/s] 15%|█▌        | 15/100 [00:02<00:10,  8.20it/s] 16%|█▌        | 16/100 [00:02<00:09,  8.59it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.65it/s] 18%|█▊        | 18/100 [00:02<00:09,  8.81it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.82it/s] 20%|██        | 20/100 [00:02<00:09,  8.86it/s] 21%|██        | 21/100 [00:02<00:09,  8.68it/s] 22%|██▏       | 22/100 [00:02<00:08,  8.82it/s] 23%|██▎       | 23/100 [00:03<00:08,  8.90it/s] 24%|██▍       | 24/100 [00:03<00:09,  7.89it/s] 25%|██▌       | 25/100 [00:03<00:10,  7.47it/s] 26%|██▌       | 26/100 [00:03<00:10,  7.23it/s] 27%|██▋       | 27/100 [00:03<00:09,  7.73it/s] 28%|██▊       | 28/100 [00:03<00:09,  7.70it/s] 30%|███       | 30/100 [00:03<00:08,  8.22it/s] 31%|███       | 31/100 [00:04<00:08,  8.55it/s] 32%|███▏      | 32/100 [00:04<00:08,  8.23it/s] 33%|███▎      | 33/100 [00:04<00:07,  8.56it/s] 34%|███▍      | 34/100 [00:04<00:07,  8.43it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.62it/s] 38%|███▊      | 38/100 [00:04<00:07,  8.69it/s] 40%|████      | 40/100 [00:05<00:06,  8.78it/s] 41%|████      | 41/100 [00:05<00:06,  8.90it/s] 42%|████▏     | 42/100 [00:05<00:06,  8.81it/s] 43%|████▎     | 43/100 [00:05<00:06,  8.91it/s] 44%|████▍     | 44/100 [00:05<00:06,  8.85it/s] 45%|████▌     | 45/100 [00:05<00:06,  9.08it/s] 46%|████▌     | 46/100 [00:05<00:06,  8.79it/s] 48%|████▊     | 48/100 [00:06<00:05,  8.85it/s] 50%|█████     | 50/100 [00:06<00:05,  8.85it/s] 51%|█████     | 51/100 [00:06<00:05,  8.69it/s] 53%|█████▎    | 53/100 [00:06<00:05,  8.81it/s] 55%|█████▌    | 55/100 [00:06<00:05,  8.84it/s] 56%|█████▌    | 56/100 [00:06<00:04,  9.04it/s] 57%|█████▋    | 57/100 [00:07<00:04,  8.94it/s] 58%|█████▊    | 58/100 [00:07<00:04,  9.02it/s] 59%|█████▉    | 59/100 [00:07<00:04,  8.87it/s] 60%|██████    | 60/100 [00:07<00:04,  8.57it/s] 61%|██████    | 61/100 [00:07<00:04,  8.85it/s] 62%|██████▏   | 62/100 [00:07<00:04,  8.80it/s] 63%|██████▎   | 63/100 [00:07<00:04,  9.07it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.71it/s] 65%|██████▌   | 65/100 [00:07<00:03,  8.99it/s] 66%|██████▌   | 66/100 [00:08<00:03,  8.97it/s] 67%|██████▋   | 67/100 [00:08<00:03,  8.95it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.90it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.73it/s] 70%|███████   | 70/100 [00:08<00:03,  8.66it/s] 71%|███████   | 71/100 [00:08<00:03,  8.86it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.82it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.86it/s] 74%|███████▍  | 74/100 [00:08<00:02,  8.98it/s] 75%|███████▌  | 75/100 [00:09<00:02,  9.03it/s] 76%|███████▌  | 76/100 [00:09<00:02,  9.04it/s] 77%|███████▋  | 77/100 [00:09<00:02,  9.10it/s] 78%|███████▊  | 78/100 [00:09<00:02,  8.93it/s] 79%|███████▉  | 79/100 [00:09<00:02,  9.07it/s] 80%|████████  | 80/100 [00:09<00:02,  8.35it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.68it/s] 84%|████████▍ | 84/100 [00:10<00:01,  8.84it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.95it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.94it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.80it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.89it/s] 91%|█████████ | 91/100 [00:10<00:00,  9.13it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.88it/s] 93%|█████████▎| 93/100 [00:11<00:00,  8.54it/s] 94%|█████████▍| 94/100 [00:11<00:00,  8.63it/s] 95%|█████████▌| 95/100 [00:11<00:00,  8.45it/s] 96%|█████████▌| 96/100 [00:11<00:00,  6.79it/s] 97%|█████████▋| 97/100 [00:11<00:00,  6.44it/s] 98%|█████████▊| 98/100 [00:11<00:00,  6.14it/s] 99%|█████████▉| 99/100 [00:12<00:00,  5.61it/s]100%|██████████| 100/100 [00:12<00:00,  6.39it/s]100%|██████████| 100/100 [00:12<00:00,  8.17it/s]
2026-02-08:01:55:13 INFO     [loggers.evaluation_tracker:247] Saving results aggregated
hf ({'pretrained': 'meta-llama/Llama-3.2-1B'}), gen_kwargs: ({}), limit: 0.25, num_fewshot: None, batch_size: 32
|    Tasks     |Version|Filter|n-shot|  Metric  |   | Value  |   |Stderr |
|--------------|------:|------|-----:|----------|---|-------:|---|------:|
|lambada_openai|      1|none  |     0|acc       |↑  |  0.2327|±  | 0.0118|
|              |       |none  |     0|perplexity|↓  |116.8077|±  |11.1754|


[run_ex2_ablations] wall_time_seconds=154.624
